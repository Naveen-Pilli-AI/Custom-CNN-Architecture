{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGmcxm8OKzJA"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/Nature_Data/Train.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmaaXCj2kqPG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,BatchNormalization,Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWSXmCYRk3rX"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_path='/content/seg_train'\n",
        "test_path='/content/seg_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZlxXhmklPMn"
      },
      "outputs": [],
      "source": [
        "train_datagen =ImageDataGenerator(rescale=1./255, validation_split=0.25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JFpOMmFlTJ2"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,  # Source directory\n",
        "        target_size=(150, 150),  # Resizes images\n",
        "        batch_size=15,\n",
        "        class_mode='categorical',subset = 'training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1c-qldHldLe"
      },
      "outputs": [],
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=15,\n",
        "    class_mode='categorical',\n",
        "    subset='validation') # set as validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1JL1i8VliAI"
      },
      "outputs": [],
      "source": [
        "def Classifier():\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(720,activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(6,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "    optimizer='Adam',metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "Classifier=Classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeanjNJymDxo"
      },
      "outputs": [],
      "source": [
        "Classifier.fit(train_generator,\n",
        "          validation_data=validation_generator,\n",
        "          steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
        "          validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "          epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "360QFFdVtNio"
      },
      "outputs": [],
      "source": [
        "Classifier.save(\"model_1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVMrUAOetfvY"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/model_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "old_classes=train_generator.class_indices\n",
        "classes= dict([(value, key) for key, value in old_classes.items()])\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "jsgIOhyOpdr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHeBfeGWtxLD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# img=cv2.imread('/content/seg_test/forest/20056.jpg')\n",
        "test_image = tf.keras.preprocessing.image.load_img('/content/seg_pred/10712.jpg',target_size = (150, 150)) # IT IS LOADING STORED IMAGE FROM CAM_IMAGES FOLDER\n",
        "test_image = tf.keras.preprocessing.image.img_to_array(test_image)  # IT IS CONVERTING IMAGE TO ARRAY FROMATE\n",
        "test_image = np.expand_dims(test_image, axis = 0)  # IT IS EXPANDING DIMENTIONS OF IMAGE LIKE (1,224,224,3)\n",
        "\n",
        "Predictions=model.predict(test_image)\n",
        "Max_val=np.argmax(Predictions) # IT GIVES THE MAX_VALUE FROM PREDICTIONS\n",
        "print('Predicted_Item :',classes[Max_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW_AZI3ZyFow"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# /content/seg_pred/10079.jpg, /content/seg_pred/10092.jpg, /content/seg_pred/10164.jpg,/content/seg_pred/10013.jpg,/content/seg_pred/1003.jpg, /content/seg_pred/10712.jpg\n",
        "img=cv2.imread('/content/seg_pred/10712.jpg')\n",
        "cv2_imshow(img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}